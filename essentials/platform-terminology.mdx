---
title: "Platform Terminology"
description: "Understand the building blocks of eigi.ai voice agents and how they connect humans with digital intelligence"
icon: "book"
---

## The eigi.ai Vision

**eigi.ai** represents a new paradigm in communicationâ€”a digital tribe where AI and humans connect seamlessly. Our platform bridges the gap between people and intelligent digital voice agents, enabling natural conversations that feel genuinely human.

Think of eigi.ai as your gateway to building digital entities that can:

- Engage in natural, flowing conversations
- Understand context and intent
- Perform actions on your behalf
- Connect with your existing systems and workflows

---

## Platform Concepts

<Info>
  An overview of the key components that make up eigi.ai voice agents and how
  they work together to create intelligent, human-like conversations.
</Info>

### Voice Agent Architecture

Every eigi.ai voice agent follows a sophisticated pipeline designed for natural, real-time conversations:

<Steps>
  <Step title="Input Medium">
    The input method determines how users interact with your agent: - **Voice**:
    Via phone call or embedded web widget (microphone input) - **Text**:
    Chat-based interaction through the widget - **Video**: Visual conversations
    with digital avatars
  </Step>

  <Step title="Speech Recognition">
    Converts spoken input into text for processing. Our platform uses advanced
    speech-to-text technology to accurately transcribe user speech in real-time,
    supporting multiple languages and accents.
  </Step>

  <Step title="Intelligence Layer">
    The brain of your agent. This layer: - Interprets user intent - Maintains
    conversation context - Generates relevant, dynamic responses - Triggers
    actions and tools when needed
  </Step>

  <Step title="Voice Synthesis">
    Transforms the agent's text response into natural-sounding speech. Choose
    from multiple voice profiles, including custom cloned voices that match your
    brand identity.
  </Step>

  <Step title="Output Delivery">
    Delivers responses back to the user through: - **Voice**: Real-time audio
    playback - **Chat**: Text messages in the widget - **Video**: Synchronized
    with digital avatars
  </Step>
</Steps>

---

## Core Components

### Agents

An **Agent** is your AI-powered digital representative. Each agent is configured with:

<CardGroup cols={2}>
  <Card title="Personality & Prompts" icon="message">
    Define how your agent speaks, its tone, and conversation style
  </Card>
  <Card title="Voice Profile" icon="microphone">
    Choose or clone a voice that represents your brand
  </Card>
  <Card title="Tools & Actions" icon="wrench">
    Connect external APIs and enable your agent to take actions
  </Card>
  <Card title="Knowledge Base" icon="brain">
    Provide context and information for your agent to reference
  </Card>
</CardGroup>

### Projects

**Projects** help you organize multiple agents under a single umbrella. Use projects to:

- Group agents by department (Sales, Support, Marketing)
- Manage different client implementations
- Separate development and production environments

### Conversations

A **Conversation** represents a single interaction session between a user and your agent. Each conversation captures:

- Full transcript of the dialogue
- Duration and timestamps
- Sentiment analysis
- Any actions or tools triggered

---

## Communication Channels

### Phone Calls

Connect your agents to phone numbers for:

<Columns cols={2}>
  <Card title="Inbound Calls" icon="phone-incoming">
    Receive calls from customers on dedicated phone numbers. Your agent handles
    inquiries 24/7.
  </Card>
  <Card title="Outbound Calls" icon="phone-outgoing">
    Initiate calls to customers for follow-ups, reminders, surveys, and outreach
    campaigns.
  </Card>
</Columns>

### Web Widget

Embed a voice-enabled chat widget directly on your website:

- One-click voice conversations
- Text chat support
- Screen sharing capabilities
- Fully customizable appearance

### Video Calls

Create immersive experiences with digital avatars:

- Human-like video representations
- Synchronized lip movements
- Professional appearance options

---

## Post-Conversation Capabilities

eigi.ai agents can perform intelligent actions after conversations end:

<AccordionGroup>
  <Accordion title="Call Summarization" icon="file-lines">
    Automatically generate concise summaries of every conversation for easy
    review and CRM integration.
  </Accordion>

  <Accordion title="Information Extraction" icon="filter">
    Extract structured data such as customer names, appointment times, product
    interests, and more.
  </Accordion>

  <Accordion title="Automated Actions" icon="bolt">
    Trigger workflows, update databases, send notifications, or invoke external
    APIs based on conversation outcomes.
  </Accordion>

  <Accordion title="Analytics & Insights" icon="chart-line">
    Track conversation metrics, sentiment trends, and agent performance over
    time.
  </Accordion>
</AccordionGroup>

---

## Key Terminology

| Term              | Definition                                                      |
| ----------------- | --------------------------------------------------------------- |
| **Agent**         | An AI-powered voice assistant configured for specific tasks     |
| **Conversation**  | A single interaction session between a user and an agent        |
| **Widget**        | Embeddable component for adding voice AI to websites            |
| **Voice Profile** | The speaking voice assigned to an agent                         |
| **Tool**          | External API or action an agent can trigger during conversation |
| **Prompt**        | Instructions that define agent behavior and personality         |
| **Avatar**        | Visual representation of an agent for video interactions        |

<Tip>
  These components work together seamlessly, and you can configure every aspect
  through the eigi.ai dashboard without writing any code.
</Tip>
